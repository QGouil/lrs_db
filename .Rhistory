swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Targetted_Technology = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Technology_in_Focus = Targetted_Technology,
Code = Source)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Targetted_Technology = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Technology_in_Focus = Targetted_Technology,
Code = Source)
library(readr)
library(jsonlite)
library(docopt)
library(pbapply)
library(magrittr)
library(futile.logger)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Targetted_Technology = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Technology_in_Focus = Targetted_Technology,
Code = Source)
tidydata <- tidyr::gather(swsheet, key = 'Technology', value = 'Val',
-Description, -Name, -Platform, -DOIs, -PubDates,
-Code, -Github, -License, -Refs, -BioC, -CRAN, -PyPI,
-Conda, -Citations, -Publications) %>%
dplyr::filter(Val == TRUE) %>%
dplyr::select(-Val) %>%
dplyr::arrange(Name)
tidydata <- tidyr::gather(swsheet, key = 'Category', value = 'Val',
-Description, -Name, -Platform, -DOIs, -PubDates,
-Code, -Github, -License, -Refs, -BioC, -CRAN, -PyPI,
-Conda, -Citations, -Publications) %>%
dplyr::filter(Val == TRUE) %>%
dplyr::select(-Val) %>%
dplyr::arrange(Name)
add_refs <- function(swsheet, titles_cache, skip_cites) {
`%>%` <- magrittr::`%>%`
futile.logger::flog.info("Adding references...")
if (skip_cites) {
msg <- "Skipping downloading of citations from Crossref!"
futile.logger::flog.warn(msg)
}
doi_list <- swsheet %>%
dplyr::mutate(DOIs = stringr::str_split(DOIs, ";")) %>%
dplyr::pull(DOIs) %>%
setNames(swsheet$Name)
ref_list <- pbapply::pbsapply(names(doi_list), function(x) {
dois <- doi_list[[x]]
if (all(is.na(dois))) {
return(NA)
}
if (!skip_cites) {
cites <- sapply(dois, function(doi) {
cite <- tryCatch({
rcrossref::cr_citation_count(doi)
}, error = function(e) {
NA
})
Sys.sleep(sample(seq(0, 1, 0.1), 1))
return(cite)
})
} else {
cites <- rep(NA, length(dois))
}
dates <- sapply(dois, function(doi) {
as.character(dplyr::pull(titles_cache[titles_cache$DOI == doi, ], "PubDate"))
})
titles <- get_titles(dois, titles_cache)
ref <- tibble::tibble(Title     = titles,
DOI       = dois,
PubDate   = dates,
Preprint  = dates == "PREPRINT",
Citations = cites)
})
pre_list <- purrr::map_if(ref_list, !is.na(ref_list),
dplyr::filter, Preprint == TRUE)
pub_list <- purrr::map_if(ref_list, !is.na(ref_list),
dplyr::filter, Preprint == FALSE)
swsheet <- swsheet %>%
dplyr::mutate(Refs = purrr::map2(pub_list, pre_list,
function(x, y) {
list(Publications = x,
Preprints = y)
})) %>%
dplyr::mutate(Citations = purrr::map_if(ref_list, !is.na(ref_list),
function(x) {sum(x$Citations)}),
Publications = purrr::map_if(pub_list, !is.na(pub_list),
nrow),
Preprints = purrr::map_if(pre_list, !is.na(pre_list),
nrow),
PubDates = purrr::map_if(ref_list, !is.na(ref_list),
function(x) {paste(x$PubDate, sep = ";")})) %>%
dplyr::mutate(Citations = purrr::flatten_dbl(Citations),
Publications = purrr::flatten_int(Publications),
Preprints = purrr::flatten_int(Preprints))
return(swsheet)
}
tidydata <- add_refs(swsheet)
skip_cites <- FALSE
tidydata <- add_refs(swsheet)
tidydata <- add_refs(swsheet, FALSE)
tidydata <- add_refs(swsheet, skip_cites = FALSE)
titles_cache <- readr::read_csv("docs/data/titles.csv",
col_types = readr::cols(
DOI   = readr::col_character(),
Title = readr::col_character(),
PubDate = readr::col_date()
)
)
tidydata <- add_refs(swsheet, titles_cache = titles_cache, skip_cites = FALSE)
get_titles <- function(dois, titles_cache) {
`%>%` <- magrittr::`%>%`
titles <- purrr::map(dois, function(doi) {
if (doi %in% titles_cache$DOI) {
titles_cache %>%
dplyr::filter(DOI == doi) %>%
dplyr::pull(Title)
} else {
NA
}
}) %>%
purrr::flatten_chr()
return(titles)
}
tidydata <- add_refs(swsheet, titles_cache = titles_cache, skip_cites = FALSE)
head(tidydata)
tidydata2 <- tidyr::gather(tidydata, key = 'Technology', value = 'Val',
-Description, -Name, -Platform, -DOIs, -PubDates,
-Code, -Github, -License, -Refs, -BioC, -CRAN, -PyPI,
-Conda, -Citations, -Publications) %>%
dplyr::filter(Val == TRUE) %>%
dplyr::select(-Val) %>%
dplyr::arrange(Name)
tidydata2 <- tidyr::gather(tidydata, key = 'Category', value = 'Val',
-Description, -Name, -Platform, -DOIs, -PubDates,
-Code, -Github, -License, -Refs, -BioC, -CRAN, -PyPI,
-Conda, -Citations, -Publications) %>%
dplyr::filter(Val == TRUE) %>%
dplyr::select(-Val) %>%
dplyr::arrange(Name)
tidydata2 <- tidyr::gather(tidydata, key = 'Category', value = 'Val',
-Description, -Name, -Platform, -DOIs, -PubDates,
-Code, -License) %>%
dplyr::filter(Val == TRUE) %>%
dplyr::select(-Val) %>%
dplyr::arrange(Name)
getwd()
library(dplyr)
# From http://stackoverflow.com/questions/1181060
stocks <- tibble(
time = as.Date('2009-01-01') + 0:9,
X = rnorm(10, 0, 1),
Y = rnorm(10, 0, 2),
Z = rnorm(10, 0, 4)
)
head(stocks)
gather(stocks, stock, price, -time)
library(tidyr)
gather(stocks, stock, price, -time)
stocks
dim(gather(stocks, stock, price, -time))
tail(gather(stocks, stock, price, -time))
stocks %>% gather(stock, price, -time)
stocks
mini_iris <- iris[c(1, 51, 101), ]
head(mini_iris)
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length)
rm(mini_iris, stocks)
titles <- readr::read_csv("docs/data/titles.csv",
col_types = readr::cols(
DOI   = readr::col_character(),
Title = readr::col_character(),
PubDate = readr::col_date()
)
)
class(titles$PubDate)
titles <- readr::read_csv("docs/data/titles.csv",
col_types = readr::cols(
DOI   = readr::col_character(),
Title = readr::col_character(),
PubDate = as.character(readr::col_date())
)
)
titles <- readr::read_csv("docs/data/titles.csv",
col_types = readr::cols(
DOI   = readr::col_character(),
Title = readr::col_character(),
PubDate = readr::col_character()
)
)
class(titles$PubDate)
ls(titles$PubDate)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types    = readr::cols(
.default   = readr::col_logical(),
Tool       = readr::col_character(),
DOI        = readr::col_character(),
Programming_Language = readr::col_character(),
Details    = readr::col_character(),
Source     = readr::col_character(),
License    = readr::col_character()
)) %>%
dplyr::rename(Name        = Tool,
Platform    = Programming_Language,
DOIs        = DOI,
Description = Details,
Code        = Source)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types    = readr::cols(
.default   = readr::col_logical(),
Tool       = readr::col_character(),
DOI        = readr::col_character(),
Programming_Language = readr::col_character(),
Details    = readr::col_character(),
Source     = readr::col_character(),
License    = readr::col_character()
)) %>%
dplyr::rename(Name        = Tool,
Platform    = Programming_Language,
DOIs        = DOI,
Description = Details,
Code        = Source)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Code = Source)
swsheet
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Code = Source)
swsheet
titles <- readr::read_csv("docs/data/titles.csv",
col_types = readr::cols(
DOI   = readr::col_character(),
Title = readr::col_character(),
PubDate = as.Date(readr::col_date())
)
)
library(rcrossref)
cr_works(swsheet[2,2])
class(cr_works(swsheet[2,2])$Date)
class(cr_works(swsheet[2,2])$data)
class(cr_works(swsheet[2,2])$data$issued)
class(as.Date(cr_works(swsheet[2,2])$data$issued))
sessionInfo()
sessionInfo()
library(readr)
library(jsonlite)
library(docopt)
library(pbapply)
library(magrittr)
library(futile.logger)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Code = Source)
sort(colnames(swsheet[14:36]))
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date"
writeLines(paste0(asterik,"\t",'<p class="text-muted">Last updated: ', datetime,
' UTC</p>'),
"docs/footer_content.html")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "'<p class="text-muted">(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date</p>'"
writeLines(paste0(asterik,"\t",'<p class="text-muted">Last updated: ', datetime,
' UTC</p>'),
"docs/footer_content.html")
cat('<p class=\"text-muted\">(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date</p>')
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- cat('<p class=\"text-muted\">(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date</p>')
writeLines(paste0(asterik,"\t",'<p class="text-muted">Last updated: ', datetime,
' UTC</p>'),
"docs/footer_content.html")
cat("'<p class=\"text-muted\">(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date</p>'")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- cat("'<p class=\"text-muted\">(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date</p>'")
writeLines(paste0(asterik,"\t",'<p class="text-muted">Last updated: ', datetime,
' UTC</p>'),
"docs/footer_content.html")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date"
writeLines(paste0('<p class="text-muted">asterik</p>',"\t",'<p class="text-muted">Last updated: ', datetime,
' UTC</p>'),
"docs/footer_content.html")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date"
writeLines(paste0('<p class="text-muted">',asterik,'</p>',"\t",'<p class="text-muted">Last updated: ', datetime,
' UTC</p>'),
"docs/footer_content.html")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date"
writeLines(paste0('<p class="text-muted">',asterik,"\t",'Last updated: ', datetime,' UTC</p>'),"docs/footer_content.html")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date"
writeLines(paste0('<p class="text-muted">',asterik,'Last updated: ', datetime,' UTC</p>'),"docs/footer_content.html")
datetime <- Sys.time()
attr(datetime, "tzone") <- "UTC"
asterik <- "(*) denotes that the tool is not updated or maintained as of the last long-read-tools database updated date"
writeLines(paste0('<p class="text-muted">',asterik,' of: ', datetime,' UTC</p>'),"docs/footer_content.html")
q <- read.table("q_list.txt")
q <- read.csv("q_list.txt")
head(q)
s <- read.csv("s_list.txt")
setdiff(q,s)
setdiff(s,q)
!intersect(s,q)
intersect(s,q)
class(q)
intersect(s$Tool,q$Tool)
!intersect(s$Tool,q$Tool)
outersectr(s$Tool,q$Tool)
outersect(s$Tool,q$Tool)
setdiff(s$Tool,q$Tool)
setdiff(q$Tool,s$Tool)
rm (q, s)
s <- read.csv("slist.txt")
q <- read.csv("qlist.txt")
setdiff(s$Tool,q$Tool)
setdiff(q$Tool,s$Tool)
swsheet <- readr::read_csv("lrs_tools_master.csv",
col_types = readr::cols(
.default = readr::col_logical(),
Tool = readr::col_character(),
DOI = readr::col_character(),
Programming_Language = readr::col_character(),
Details = readr::col_character(),
Source = readr::col_character(),
License = readr::col_character()
)) %>%
dplyr::rename(Name = Tool,
Platform = Programming_Language,
DOIs = DOI,
Description = Details,
Code = Source)
swsheet <- sort(swsheet)
tail(swsheet[order(swsheet$Name),]
)
install.packages("Rsamtools")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Rsamtools", version = "3.8")
library(Rsamtools)
blFls <-  BamFileList("../../../../../Nadeeka/human_cell_line/")
ls(blFls)
head(blFls)
blFls <-  BamFileList("../../../../../Nadeeka/human_cell_line/*.bam")
head(blFls)
list.files("$BAM", "../../../../../Nadeeka/human_cell_line/*.bam")
list.files(path = "../../../../../Nadeeka/human_cell_line/", pattern="bam$", full.names = T)
blFls <-  BamFileList(list.files(path = "../../../../../Nadeeka/human_cell_line/", pattern="bam$", full.names = T))
blFls
blFls <-  Rsamtools :: BamFileList(list.files(path = "../../../../../Nadeeka/human_cell_line/", pattern="bam$", full.names = T))
blFls
list.files(path = "../../../../../Nadeeka/human_cell_line/", pattern="bam$", full.names = F)
text("De novo", font = 2)
text(1,1,"De novo", font = 2)
italic("de-Novo")
expression(italic("denovo"))
'*italic(C.~austriacus)*'
substitute(paste(italic('p value'), " = 0.01"))
substitute(italic('p value'), " = 0.01")
substitute(italic('p value'))
getwd()
